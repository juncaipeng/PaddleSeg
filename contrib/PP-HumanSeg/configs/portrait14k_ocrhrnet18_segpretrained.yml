batch_size: 8    # 4 GPUs
iters: 50000
save_interval: 500

train_dataset:
  type: Dataset
  mode: train
  dataset_root: data/portrait14k
  train_path: data/portrait14k/train.txt
  num_classes: 2
  transforms:
    - type: Resize
      target_size: [398, 224]
    - type: ResizeStepScaling
      scale_step_size: 0
    - type: RandomRotation
    - type: RandomPaddingCrop
      crop_size: [398, 224]
    - type: RandomHorizontalFlip
    - type: RandomDistort
    - type: RandomBlur
      prob: 0.3
    - type: Normalize

val_dataset:
  type: Dataset
  mode: val
  dataset_root: data/portrait14k
  val_path: data/portrait14k/val.txt
  num_classes: 2
  transforms:
    - type: Resize
      target_size: [398, 224]
    - type: Normalize

export:
  transforms:
    - type: Resize
      target_size: [398, 224]
    - type: Normalize

optimizer:
  type: sgd
  momentum: 0.9
  weight_decay: 0.0005

lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.001
  end_lr: 0
  power: 0.9

loss:
  types:
    - type: MixedLoss
      losses:
        - type: CrossEntropyLoss
        - type: LovaszSoftmaxLoss
      coef: [0.8, 0.2]
  coef: [1, 0.4]

model:
  type: OCRNet
  backbone:
    type: HRNet_W18
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/hrnet_w18_ssld.tar.gz
  num_classes: 2
  backbone_indices: [0]
  pretrained: output/mixed_dataset_ocrnet_hrnet18/test_0/best_model/model.pdparams
